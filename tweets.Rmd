---
title: "Final Project"
author: "Group L"
output:
  html_document:
    toc: true
    self_contained: true
    keep_md: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message=FALSE))
```


# Overview

For this project, we explored two datasets -- tweets about Covid-19 vaccine and the reported side effects of it.
Firstly, we looked into what people are discussing when they tweet about Covid-19 vaccine. Then we narrowed it down to the side effect discussions, to see what's commonly mentioned here and where the tweets were sent.
Secondly, we focused on the adverse reactions reported from 2020-12-01 to 2021-3-31. The visualization aims to provide an insight into who are the people reporting side effects and how do they compare to the general population; the most common reported symptoms etc. We also analyzed tweets associated with the covid-19 vaccine to see people's attitudes on the vaccine.

# Data

- All COVID-19 Vaccines Tweets
https://www.kaggle.com/gpreda/all-covid19-vaccines-tweets
- Vaccine Adverse Event Reporting System (VAERS)1 established by the Food and Drug Administration (FDA) and the Centers for Disease Control and Prevention (CDC) 
https://vaers.hhs.gov/data/datasets.html?
- Allocations of Covid-19 vaccines produced by Pfizer and Moderna into different States by CDC https://data.cdc.gov/Vaccinations/COVID-19-Vaccine-Distribution-Allocations- by-Juris/saz5-9hgg https://data.cdc.gov/Vaccinations/COVID-19-Vaccine-Distribution-Allocations- by-Juris/b7pe-5nws
- COVID-19 Vaccination Demographic Data. Vaccination by age. https://www.cdc.gov/coronavirus/2019-ncov/vaccines/distributing/demographics-vaccination-data.html
- State-by-state data on COVID-19 vaccinations in the United States 
https://ourworldindata.org/us-states-vaccinations

# Tweets about Covid-19 Vaccine

## What Do People Tweet about Covid-19 Vaccines ? 

```{r include=FALSE}
library(tidyverse)
library(tm)
library(stopwords)
library(tidytext)
library(wordcloud)
library(tidyverse)
library(hunspell)
library(data.table)
library(readxl)
library(igraph)
library(ggthemes)
library(ggplot2)
library(igraph)
library(tibble)
library(plotly)
library(network)
library(DT)
library(wordcloud)
library(sna)
library(visNetwork)
library(ggrepel)
library(networkD3)
library(gridExtra)
# library(RColorBrewer)

tweet <- fread("./tweet_data_QH/vaccination_all_tweets_ansi.csv")
```


```{r}
load("./tweet_data_QH/term_stemmed_all.RData")
```

```{r eval=FALSE, include=FALSE}
# str(tt)
# all oringinal tweets

# clean text
tt <- tweet[,c("id","text")]
tt <- rename(tt, "doc_id" = 'id')
tt$text <- as.character(tt$text)
# make a corpus
library(tm)
tt_source <- DataframeSource(tt)
tt_corpus <- VCorpus(tt_source)
tt_corpus


library(stopwords)
# preprocessing function----
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeWords, c(stopwords(source = "smart")))
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, stripWhitespace)
  return(corpus)
}
# preprocessing
tt_clean <- clean_corpus(tt_corpus)
tt_dtm <- DocumentTermMatrix(tt_clean)

library(tidytext)
tt_tidy <- tidy(tt_dtm)
# mannually remove residual unwanted words
tt_tidy <- tt_tidy %>% 
  filter(grepl("[a-z]*\\…",term) == F) %>% 
  filter(grepl("http([a-z]*[A-Z]*[0-9]*)*",term) == F) %>% 
  # filter(grepl("([A-Z]*[a-z]*)*'([A-Z]*[a-z]*)*'",term) == F) %>% # 去除
  filter(term != "the") %>% 
  filter(term != "this") %>% 
  group_by(term) %>% 
  mutate(n=n()) %>% 
  arrange(desc(n))

tt_tidy$term2 <- hunspell::hunspell_stem(tt_tidy$term,"en_US")
ttt <- tt_tidy
ttt$term2 <- lapply(ttt$term2, function(x) if(identical(x, character(0))) NA_character_ else x)
stem1 <- ttt %>% 
  ungroup() %>% 
  mutate(index = row_number())%>% 
  unnest(term2)
stem1 <- stem1 %>% mutate(term3 = ifelse(is.na(term2),term,term2))
stemmed_all <- stem1[c(1,7,3)] %>% 
  rename(term = term3) %>% 
  group_by(term) %>% 
  mutate(n = sum(count)) %>% 
  arrange(desc(n))
save(stemmed_all,file = "term_stemmed_all.RData")
```

```{r echo=FALSE}
# plot word cloud
library(wordcloud)
set.seed(377)
library(RColorBrewer)
# reds <- brewer.pal(5, "RdPu")
purple_orange <- brewer.pal(10, "RdYlBu")
stemmed_all_p <- unique(stemmed_all
                    [c(2,4)]) # dataset for plotting
# save(stemmed_p,file = "term_stemmed.RData")
wordcloud(stemmed_all_p$term,stemmed_all_p$n,
          max.words = 500, color=purple_orange, scale=c(3,0.5),min.freq = 600)
```

This wordcloud includes the popular keywords (appeared more than 600 times) used in tweeting about Covid-19 vaccine.  
The most commonly mentioned word is of course "vaccine", followed by "moderna" and "covid", while "pfizer" and "pfizerbiontech" are much smaller.   
We can also see the variants of alias of Covid-19 vaccine ("covaxin", "covidvaccine"), and keywords used commonly in describing experiences ("dose","receive","today") mentioned for many times.  

## A Co-occurrence Network of Keywords

```{r include=FALSE}
library(tidyverse)
library(tidyr)
library(rlist)
library(igraph)
library(ggnetwork)
library(networkD3)
```

```{r eval=FALSE, include=FALSE}
# make an co-occurence matrix
list1k <- stemmed_all[,c(2,4)] %>% unique() %>% arrange(desc(n)) %>% head(1000) #n>=67
top1k <- stemmed_all %>% filter(term %in% list1k$term)
words <- top1k[,c(2,1)]

cooc <- merge(words,words,by='document')
cooc <- cooc %>%
  filter(term.x != term.y) %>% # remove one's relation with it self
  count(term.x,term.y) # times of co-ocurrence
cooc <- cooc %>% arrange(desc(n))
# remove replecate records (undirected edges)
cooc <- cooc %>% rename(from=term.x) %>% rename(to=term.y)
cooc2 <- cooc %>% filter(n>=100)
library(tidyverse)
dedup <- cooc2 %>%
  mutate(normalized = map2_chr(from, to, ~paste(sort(c(.x, .y)),
                                                collapse = ""))) %>%
  group_by(normalized,n) %>%
  summarise(from = first(from),
            to = first(to)) %>%
  ungroup() %>%
  select(-normalized) %>%
  arrange(desc(n))
uniedge <- dedup[,c(2,3,1)]
# save(cooc, file = "coocedge.Rdata")
# save(uniedge, file = "uniquedges.Rdata")
# library(readr)
# write_csv(cooc, path = "coocedge.csv")
```

```{r}
load("./tweet_data_QH/coocedge.Rdata")
load("./tweet_data_QH/uniquedges.Rdata")
```


```{r include=FALSE}
# make a graph----
edges <- as.matrix(uniedge)
g <- graph_from_data_frame(edges, directed = F, vertices = NULL)
# # g
# # calculate indegree and outdegree (centrality)
# V(g)$deg <- degree(g, mode = "total", loops = F, normalized = FALSE)
# # add weight(n) as edge width
# E(g)$width <- E(g)$n
# # as_data_frame(g, what="edges") 
# # g
# # plot(g)
```

```{r include=FALSE}
# # prepare data for plotting----
# library(ggnetwork)
# set.seed(12)
# # class(g)
# # summary(g)
# df <- ggnetwork(g,layout = with_kk())
# # df
# att <- rename(unique(stemmed_all[,c(2,4)]),name = term)
# df <- left_join(df,att,by="name")
# df$width <- as.numeric(df$width)/100
# 
#find clusters
wc <- cluster_walktrap(g,weights = E(g)$width)  # find "communities"
# # class(c)
# # sizes(wc)
members <- membership(wc)
mm <- as.data.frame(cbind(names(members),members)) %>% rename(.,name=V1) %>% rename(.,cluster=members)
# # ignore tiny groups
# mm_b <- mm %>% group_by(cluster) %>% 
#   mutate(n = n()) %>% 
#   mutate(group = ifelse(n>=5,n,1))
# # summary(as.factor(mm_b$group))
# # name the groups
# mm_b$group <- as.factor(mm_b$group) # numeric to factor
# mm_b$group <- ordered(mm_b$group, levels = c(1,7,23,37,212), labels = c("undefined","group1","group2","group3","group4"))
# mm_b$group <- as.character(mm_b$group)
# df_m <- merge(mm_b,df,by='name')
# 
# # # plot the clusters
# # cp <- unique(df_m[,c(1,4)])
# # library(ggthemes)
# # cp %>% ggplot(aes(name,group)) +
# #   geom_jitter(height = 0.2) +
# #   theme_clean() +
# #   labs(title = "Automatically Detected Clusters",
# #        tag = "Figure 2",
# #        y = "cluster") +
# #   theme(axis.text.x = element_blank(),axis.title.x = element_blank()) +
# #   scale_colour_manual(values = c("blue", "green", "red")) +
# #   labs(color='Party')
# 
# ```
# 
# ```{r eval=FALSE, include=FALSE}
# # plotting network
# ggplot(df_m, aes(x, y, xend = xend, yend = yend)) +
#   geom_edges(aes(size = width),alpha = 0.2,color="seashell3",curvature = 0.2) +
#   geom_nodes(data=subset(df_m, group=="undefined"),aes(size=n.y), color = "gray3", alpha = 0.5) + # terms not in big clusters
#   geom_nodes(data=subset(df_m, group=="group1"),aes(size=n.y), color = "darkred", alpha = 0.5) + # group1
#   geom_nodes(data=subset(df_m, group=="group2"),aes(size=n.y), color = "blue4", alpha = 0.5) + # group2
#   geom_nodes(data=subset(df_m, group=="group3"),aes(size=n.y), color = "purple", alpha = 0.5) + # group3
#   geom_nodes(data=subset(df_m, group=="group4"),aes(size=n.y), color = "orange", alpha = 0.5) + # group4
#   geom_nodetext_repel(aes(label = name),size = 2.5) + 
#   theme_blank()
# # no text for central nodes ---- try interactive graph

```

```{r echo=FALSE}
library(networkD3)
# Convert to object suitable for networkD3
g_d3 <- igraph_to_networkD3(g, group = members)
# Create force directed network plot
forceNetwork(Links = g_d3$links, Nodes = g_d3$nodes, 
             Source = 'source', Target = 'target', 
             NodeID = 'name', Group = 'group',
             fontSize = 50, fontFamily = "Times New Roman",
             zoom = T)
# no specifying link width (would look messy)
```

```{r eval=FALSE, include=FALSE}
## Sentiment Analysis

twi <- read_excel("./twi_sentiment_YL/DV_sentiment_NEW.xlsx")
twi <- as.data.table(twi)

twi<-twi%>%
mutate(Sentiment=ifelse(sentiment>= 0.05,"positive",ifelse(sentiment <= -0.05,"negative","neutral")))

twi<-twi%>%
mutate(twi_date=as.Date(twi$date,format="%Y-%m-%d"))%>%
mutate(td= format(as.Date(twi_date, "%m/%d/%Y"),"%Y-%m"))
save(twi,file="twi.RData")
```


```{r include=FALSE}
load("./twi_sentiment_YL/twi.RData")
```

## Sentiment State Distribution of Tweets
```{r include=FALSE}
three <- twi%>%
  select(Sentiment)%>%
  group_by(Sentiment)%>%
  count(Sentiment)
```

```{r echo=FALSE}
ggplot(three, aes(x=Sentiment, y=n, fill=Sentiment)) +
  geom_bar(stat="identity")+theme_minimal()+labs(x = "Sentiment Categories", y = "Number of Tweets",
       title = "Sentiment State Distribution of Tweets")+theme(legend.position="none")+ 
scale_fill_manual("legend", values = c("positive" = "#FF6666", "neutral" = "#faead3", "negative" = "#106d9c"))
```

We clean the text data of all the tweets about vaccines, and then we apply vader sentiment analysis, so we classify all tweets into three categories: positive tweets, neutral tweets and negative tweets.

Now we can see people's attitude towards vaccines.

We can find from the bar chart that most tweets about vaccines are neutral one or positive one. Negative sentiment is not widely available.


```{r echo=F,include=FALSE}
num<-twi%>%
  select(twi_date,Sentiment)%>%
  group_by(twi_date,Sentiment)%>%
  count(twi_date,Sentiment)
```


```{r echo=FALSE, r,echo=F}
ggplot(num, aes(x = twi_date, y = n,colour= Sentiment)) +scale_x_date(breaks = "25 day")+ theme_minimal()+geom_line(size=1.2)+labs(x = "Date of Tweets", y = "Number of Tweets",
       title = "Timeline showing Sentiment of Tweets about COVID-19 Vaccines") + scale_color_manual(values=c("#106d9c", "yellow",  "#FF6666"))
```

Trends over time of numbers of tweets posted of three sentiment types are similar, maybe because there is no special events affects people's attitude.


```{r include=FALSE}
pos <-  read_csv("./twi_sentiment_YL/pos.csv")
neu <-  read_csv("./twi_sentiment_YL/neu.csv")
neg <-  read_csv("./twi_sentiment_YL/neg.csv")
```


```{r echo=F}
set.seed(12)
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "Positive")
wordcloud(words = pos$tokenize, freq = pos$n, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

```{r echo=F}
set.seed(12)
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "Negative")
wordcloud(words = neg$tokenize, freq = neg$n, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

```{r echo=FALSE}
set.seed(12)
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "Neutral")
wordcloud(words = neu$tokenize, freq = neu$n, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

We select top 50 common words for each types of tweets.

After seeing the common words of positive, neutral and negative  tweets, we find people share their happiness about the arrival of vaccines and give positive feedback after receiving a shot in positive tweets; neutral tweets are just  objective statements of vaccines news or information; people worry about the side effect of vaccines and whether vaccines will work in negative tweets.


## Portrait of Popular Tweets and Users
```{r include=FALSE}
favor<-twi%>%
  select(favorites,Sentiment)%>%
  arrange(-favorites)%>%  
  slice(1:15)
```


```{r echo=FALSE}
ggplot(data=favor,aes(y=as.factor(favorites), x=favorites,fill=Sentiment) ) + 
  geom_bar(stat="identity")+labs(x = "Number of Times it was Favorited", y = "Tweets",
       title = "Sentiment State of Top 15 Popular Tweets base on favorited times ")+theme_minimal()+  theme(
        axis.text.y=element_blank(),axis.ticks.y=element_blank())+ geom_text(aes(label=paste0(favorites)), vjust=0.5,hjust=1)+ 
scale_fill_manual("legend", values = c("positive" = "#FF6666", "neutral" = "#faead3", "negative" = "#106d9c"))
```

We can see sentiment attribute of popular tweets(base on favorited times). Most of top 15 popular tweets are neutral one or positive one, which means that people didn't show a preference for negative tweets.

```{r include=FALSE}
retwe<-twi%>%
  select(retweets,Sentiment)%>%
  arrange(-retweets)%>%  
  slice(1:15)
```


```{r echo=FALSE}
ggplot(data=retwe,aes(y=as.factor(retweets), x=retweets,fill=Sentiment) ) + 
  geom_bar(stat="identity")+labs(x = "Number of Times it was Retweeted", y = "Tweets",
       title = "Sentiment State of Top 15 Popular Tweets base on retweeted times ")+theme_minimal()+ theme(
        axis.text.y=element_blank(),axis.ticks.y=element_blank())+ geom_text(aes(label=paste0(retweets)), vjust=0.5,hjust=1)+ 
scale_fill_manual("legend", values = c("positive" = "#FF6666", "neutral" = "#faead3", "negative" = "#106d9c"))
```

We can see sentiment attribute of popular tweets(base on retweeted times). Most of top 15 popular tweets still are neutral one or positive one, which means that people didn't show a preference for retweeting negative tweets and maybe kept positive attitude towards effect of vaccines.

```{r include=FALSE}
follow <-  read_csv("./twi_sentiment_YL/follow.csv")%>%
  mutate(Sentiment=sent_ca)

```


```{r echo=FALSE}
ggplot(follow, aes(x=factor(user_name), fill=Sentiment))+
  geom_bar(width=0.7)+
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 70, hjust = 0.5, 
                              vjust = 0.5,color = "black",size=9))+labs(x = "User Name", y = "Number of Tweets",
       title = "Sentiment State of Tweets of Top 10 Users who have most followers ")+ 
scale_fill_manual("legend", values = c("positive" = "#FF6666", "neutral" = "#faead3", "negative" = "#106d9c"))
```

We also check tweets of popular users(base on number of followers they have), because they have great influence among the public. Most of these users mainly post objective statements of vaccines news or information and they show more positive sentiment than negative sentiment.


# Tweets about Covid-19 Vaccine's Side Effects

```{r echo=FALSE}
# the proportion of side effect discussions in all tweets
library(ggplot2)
data <- data.frame(
  group=c("side effect","other"),
  value=c(983,48622))

# Compute the position of labels
data <- data %>% 
  arrange(desc(group)) %>%
  mutate(prop = value / sum(data$value) *100) %>%
  mutate(ypos = cumsum(prop)- 0.5*prop )

# Basic piechart
ggplot(data, aes(x="", y=prop, fill=group)) +
  geom_bar(stat="identity", width=1,fill=c("#2d004b","#fdb863")) + # c("#8073ac","#fbd263")
  coord_polar("y", start=0) +
  theme_void() +
  geom_text(aes(y = ypos, label = value), color = "white", size=6) + labs(title = "Proportion of side effect discussions")
```

Side effect is not really a heated topic among the discussions on twitter. Only 1/50 of all the tweets about Covid-19 vaccine mention side effects.  

```{r}
# the relative volume of manufacturer names in side effect discussions compared with that in all tweets
library(dplyr)
load("./tweet_data_QH/term_stemmed_all.RData")
manu <- stemmed_all %>% filter(term %in% c("moderna","pfizer","pfizerbiontech"))
unimanu <- manu[,c(2,4)] %>% unique()
# moderna:11222
# pfizer:7257

load("./tweet_data_QH/se_term_stemmed_all.RData")
manuse <- stemmed %>% filter(term %in% c("moderna","pfizer","pfizerbiontech"))
unimanuse <- manuse[,c(2,4)] %>% unique()
# moderna:416
# pfizer:158


# n1 <- c(11222,7257)
# n2 <- c(416,158)
# manufacturer <- c("moderna","pfizer")
# cpm <- data.frame(manufacturer,n1,n2)
# cpm <- cpm %>% mutate(p = n2/n1)

manufacturer <- c("moderna","moderna","moderna","pfizer","pfizer","pfizer")
group <- c("all","side effect","relative","all","side effect","relative")
n <- c(11222,416,0.037,7257,158,0.022)
cpm <- data.frame(manufacturer,group,n)

cpm[c(-3,-6),] %>% ggplot() +
  geom_col(aes(manufacturer,n,fill=group),position = position_dodge2(preserve = "single")) +
  labs(title = "Occurrences of manufacturer's names ",
       x="Manufacturer",
       y = "Occurrences") + 
  theme_minimal() + 
  scale_fill_manual(values = c("#fdb863","#2d004b"))
```

Moderna has larger volume in both all tweets and tweets about side effects, compared to Pfizer.  
  
```{r echo=FALSE}
cpm[c(3,6),] %>% ggplot() +
  geom_col(aes(manufacturer,n,fill=manufacturer)) + 
  labs(title = "Proportion of Occurrences of manufacturer's names",
       x="Manufacturer",
       y = "p") + 
  theme_minimal() + 
  scale_fill_manual(values = c("#fdb863","#2d004b"),labels = c("moderna", "pfizer"))
```

Looking at the proportion of side-effect-relevant tweets in all tweets for each manufacturer, moderna still scores higher than pfizer, which means it may be more likely to trigger side effects. Just a thought to be tested for in later analyses.  

## What Do They Tweet about Covid-19 Vaccine's Side Effects ? 

```{r eval=FALSE, include=FALSE}
# all tweets mentioned "side effect" or "sideeffect"
setweet <- read.csv("./tweet_data_QH/tweet_side_effect.csv")
setweet <- unique(setweet)

# clean text
tt <- setweet[,c("id","text")]
tt <- rename(tt, "doc_id" = 'id')
tt$text <- as.character(tt$text)
# make a corpus
library(tm)
tt_source <- DataframeSource(tt)
tt_corpus <- VCorpus(tt_source)
tt_corpus


library(stopwords)
# preprocessing function----
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeWords, c(stopwords(source = "smart")))
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, stripWhitespace)
  return(corpus)
}
# preprocessing
tt_clean <- clean_corpus(tt_corpus)
tt_dtm <- DocumentTermMatrix(tt_clean)

library(tidytext)
tt_tidy <- tidy(tt_dtm)
# mannually remove residual unwanted words
tt_tidy <- tt_tidy %>% 
  filter(grepl("[a-z]*\\…",term) == F) %>% 
  filter(grepl("http([a-z]*[A-Z]*[0-9]*)*",term) == F) %>% 
  # filter(grepl("([A-Z]*[a-z]*)*'([A-Z]*[a-z]*)*'",term) == F) %>% # 去除
  filter(term != "the") %>% 
  filter(term != "this") %>% 
  group_by(term) %>% 
  mutate(n=n()) %>% 
  arrange(desc(n))

tt_tidy$term2 <- hunspell::hunspell_stem(tt_tidy$term,"en_US")
ttt <- tt_tidy
ttt$term2 <- lapply(ttt$term2, function(x) if(identical(x, character(0))) NA_character_ else x)
stem1 <- ttt %>% 
  ungroup() %>% 
  mutate(index = row_number())%>% 
  unnest(term2)
stem1 <- stem1 %>% mutate(term3 = ifelse(is.na(term2),term,term2))
stemmed <- stem1[c(1,7,3)] %>% 
  rename(term = term3) %>% 
  group_by(term) %>% 
  mutate(n = sum(count)) %>% 
  arrange(desc(n))
save(stemmed,file = "term_stemmed_side_effect.RData")
```

```{r include=FALSE}
load("term_stemmed_side_effect.RData")
```

```{r echo=FALSE}
# plot word cloud
library(wordcloud)
set.seed(377)
library(RColorBrewer)
# reds <- brewer.pal(5, "RdPu")
purple_orange <- brewer.pal(10, "RdYlBu")
stemmed_p <- unique(stemmed[c(2,4)]) # dataset for plotting
# save(stemmed_p,file = "term_stemmed.RData")
wordcloud(stemmed_p$term,stemmed_p$n,
          max.words = 500, color=purple_orange, scale=c(3.5,0.5),min.freq = 20)
```

Given the dataset shrinks a lot when we restrict it to side effect discussions, wordcloud covers words appeared more than 20 times.
The most commonly mentioned word, in this case, is of course "side effect", followed by "moderna" and "vaccine", while "pfizer" and "pfizerbiontech" are much smaller, in line with what we found in all of the Covid-19 vaccine tweets.    
We can also see the keywords "covid","day","shot","arm","dose", which indicates many of these tweets may be records of people's vaccination experience.     
Words like "sore","fatigue","pain" and "headache" indicates the commonly mentioned side effects in tweets.  

